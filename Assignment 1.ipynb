{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e7877d",
   "metadata": {},
   "source": [
    "# Assignmnet 1 (100 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b6d20",
   "metadata": {},
   "source": [
    "**Name:** <br>\n",
    "**Email:** <br>\n",
    "**Group:** A/B <br>\n",
    "**Hours spend *(optional)* :** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f79f88",
   "metadata": {},
   "source": [
    "### Question 1: Zipf’s law *(20 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4953e4",
   "metadata": {},
   "source": [
    "<p>Verify Zipf’s law on a textual corpus. The jungle book dataset is provided in the \"Datasets and Resources\" file. (You can also use any other dataset of your choice). <p>\n",
    "\n",
    "<p> Provide a list of unique word sorted by their frequency in descending order. Also, give a brief discussion of the findings. You can use matplotlib library to plot the linear curve, and a log-log curve. The usage of other python modules is not permitted.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0cc515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "286d65b8",
   "metadata": {},
   "source": [
    "### Question 2: Mutual Information *(30 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7a1db",
   "metadata": {},
   "source": [
    "<p>Pointwise mutual information quantifies the statistical dependence between events ${x_{t} = w_{1} }$ and ${ x_{t+1} = w_{2}}$. ${C(w)}$ is the absolute frequency and ${N}$ is the size of the corpus. If the probability of the next word in the corpus (${w_{2}}$) is affected by the probability of the previous word (${w_{1}}$), then ${pmi(w_{1},w_{2}) = 0}$; else the pmi value is either positive or negative. </p>\n",
    "\n",
    "$$ pmi(w_{1},w_{2}) = log \\frac{P(x_{t} = w_{1}, x_{t+1} = w_{2})} {P(x_{t} = w_{1}) . P(x_{t+1} = w_{2})} \\approx log \\frac {C(w_{1}w_{2}) . N} {C(w_{1}) . C(w_{2})}  $$\n",
    "\n",
    "<p>Calculate the Pointwise mutual information (PMI) for all successive word pairs (w1, w2) in the jungle book corpus. Words (not word pairs) that occur in the corpus less than 10 times should be ignored. List the 30 word pairs with the highest pmi value and the 30 word pairs with the lowest pmi value. Document your observations and discuss the validity of the independence assumption for unigram models. If needed, you can use nltk library. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc1980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0558e127",
   "metadata": {},
   "source": [
    "### Question 3: Wikipedia language model *(50 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616576f",
   "metadata": {},
   "source": [
    "<p> A customer of yours is dissatisfied with the quality of the speech recognition. After a conversation with the customer, you find out that he dictates books. The initial investigations on a book excerpt have shown that the language model used is not suitable. For building a better language model for the application, you have asked your customer to provide a text from the book (see \"Datasets and Resources\") </p>\n",
    "\n",
    "<p> In order to save costs and also to avoid problems with copyrights, your company has decided not to use existing solutions for this project. So, you have to implement a 2-gram language model in Python from scratch. Include a short description of the data preprocessing steps, method, experiment design, hyper-parameters, and evaluation metric. Also, document your findings, drawbacks, and potential improvements.</p>\n",
    "\n",
    "<p> You can use nltk library. If you need to use special Python modules, you can discuss with your instructor before submission. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4776f",
   "metadata": {},
   "source": [
    "<h4> Datasets and Resources </h4> \n",
    "\n",
    "* WikiText-2 (raw/unprocessed), Train, Dev, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c70eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55cbc82a",
   "metadata": {},
   "source": [
    "### Additional Experiments *(5 additional points - <span style=\"color: red;\">Optional</span>)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5820d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
